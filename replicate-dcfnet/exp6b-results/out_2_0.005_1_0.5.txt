Pytorch version:
0.2.0_2
Output name: out_2_0.005_1_0.5
Outputting debug data to: out_2_0.005_1_0.5.txt
Outputting matlab data to: out_2_0.005_1_0.5.mat
Subspace projection ON
Noisy test set OFF
Epoch 0: lr = 0.005000
[1,    10] loss: 2.30152
[1,    20] loss: 2.27168
[1,    30] loss: 2.24834
[1,    40] loss: 2.23903
[1,    50] loss: 2.21519
[1,    60] loss: 2.22773
[1,    70] loss: 2.21000
[1,    80] loss: 2.22926
[1,    90] loss: 2.23135
[1,   100] loss: 2.23963
[1,   110] loss: 2.23516
[1,   120] loss: 2.22377
[1,   130] loss: 2.20925
[1,   140] loss: 2.22604
[1,   150] loss: 2.21396
[1,   160] loss: 2.18230
[1,   170] loss: 2.17689
[1,   180] loss: 2.20570
[1,   190] loss: 2.22044
[1,   200] loss: 2.18013
[1,   210] loss: 2.20097
[1,   220] loss: 2.18195
[1,   230] loss: 2.18470
[1,   240] loss: 2.19450
[1,   250] loss: 2.13298
[1,   260] loss: 2.18238
[1,   270] loss: 2.18142
[1,   280] loss: 2.19980
[1,   290] loss: 2.16502
[1,   300] loss: 2.17150
[1,   310] loss: 2.15084
[1,   320] loss: 2.16417
[1,   330] loss: 2.21512
[1,   340] loss: 2.25134
[1,   350] loss: 2.25312
[1,   360] loss: 2.20826
[1,   370] loss: 2.17399
[1,   380] loss: 2.18498
[1,   390] loss: 2.19533
--> Accuracy after epoch 0: 14 %
Epoch 1: lr = 0.005000
[2,    10] loss: 2.17487
[2,    20] loss: 2.19923
[2,    30] loss: 2.21595
[2,    40] loss: 2.23252
[2,    50] loss: 2.18478
[2,    60] loss: 2.19231
[2,    70] loss: 2.15115
[2,    80] loss: 2.21861
[2,    90] loss: 2.16727
[2,   100] loss: 2.18867
[2,   110] loss: 2.16628
[2,   120] loss: 2.22658
[2,   130] loss: 2.22519
[2,   140] loss: 2.17839
[2,   150] loss: 2.16311
[2,   160] loss: 2.18729
[2,   170] loss: 2.22859
[2,   180] loss: 2.12965
[2,   190] loss: 2.15558
[2,   200] loss: 2.17877
[2,   210] loss: 2.17398
[2,   220] loss: 2.17099
[2,   230] loss: 2.19399
[2,   240] loss: 2.14679
[2,   250] loss: 2.16139
[2,   260] loss: 2.14330
[2,   270] loss: 2.14646
[2,   280] loss: 2.18463
[2,   290] loss: 2.18706
[2,   300] loss: 2.18279
[2,   310] loss: 2.15412
[2,   320] loss: 2.18484
[2,   330] loss: 2.14307
[2,   340] loss: 2.17018
[2,   350] loss: 2.14239
[2,   360] loss: 2.16999
[2,   370] loss: 2.15681
[2,   380] loss: 2.15185
[2,   390] loss: 2.16706
--> Accuracy after epoch 1: 16 %
Epoch 2: lr = 0.005000
[3,    10] loss: 2.16254
[3,    20] loss: 2.18053
[3,    30] loss: 2.12924
[3,    40] loss: 2.14388
[3,    50] loss: 2.14633
[3,    60] loss: 2.14144
[3,    70] loss: 2.16340
[3,    80] loss: 2.12048
[3,    90] loss: 2.13386
[3,   100] loss: 2.15757
[3,   110] loss: 2.16381
[3,   120] loss: 2.17404
[3,   130] loss: 2.15055
[3,   140] loss: 2.14855
[3,   150] loss: 2.14133
[3,   160] loss: 2.16144
[3,   170] loss: 2.16140
[3,   180] loss: 2.16783
[3,   190] loss: 2.16408
[3,   200] loss: 2.15283
[3,   210] loss: 2.15727
[3,   220] loss: 2.14871
[3,   230] loss: 2.12602
[3,   240] loss: 2.15611
[3,   250] loss: 2.14209
[3,   260] loss: 2.11453
[3,   270] loss: 2.14889
[3,   280] loss: 2.12791
[3,   290] loss: 2.12399
[3,   300] loss: 2.15806
[3,   310] loss: 2.15011
[3,   320] loss: 2.16068
[3,   330] loss: 2.13905
[3,   340] loss: 2.16360
[3,   350] loss: 2.15168
[3,   360] loss: 2.15312
[3,   370] loss: 2.11653
[3,   380] loss: 2.13024
[3,   390] loss: 2.11942
--> Accuracy after epoch 2: 15 %
Epoch 3: lr = 0.005000
[4,    10] loss: 2.17739
[4,    20] loss: 2.18675
[4,    30] loss: 2.15587
[4,    40] loss: 2.11421
[4,    50] loss: 2.13834
[4,    60] loss: 2.14630
[4,    70] loss: 2.12966
[4,    80] loss: 2.12495
[4,    90] loss: 2.15595
[4,   100] loss: 2.17237
[4,   110] loss: 2.15514
[4,   120] loss: 2.13225
[4,   130] loss: 2.15463
[4,   140] loss: 2.13572
[4,   150] loss: 2.10292
[4,   160] loss: 2.13935
[4,   170] loss: 2.14404
[4,   180] loss: 2.10917
[4,   190] loss: 2.09341
[4,   200] loss: 2.13117
[4,   210] loss: 2.12436
[4,   220] loss: 2.12667
[4,   230] loss: 2.11817
[4,   240] loss: 2.15789
[4,   250] loss: 2.12761
[4,   260] loss: 2.09094
[4,   270] loss: 2.10660
[4,   280] loss: 2.10478
[4,   290] loss: 2.11723
[4,   300] loss: 2.13709
[4,   310] loss: 2.10495
[4,   320] loss: 2.12356
[4,   330] loss: 2.12152
[4,   340] loss: 2.14286
[4,   350] loss: 2.11785
[4,   360] loss: 2.10975
[4,   370] loss: 2.12081
[4,   380] loss: 2.08328
[4,   390] loss: 2.09576
--> Accuracy after epoch 3: 19 %
Epoch 4: lr = 0.005000
[5,    10] loss: 2.10517
[5,    20] loss: 2.09625
[5,    30] loss: 2.13708
[5,    40] loss: 2.09411
[5,    50] loss: 2.11845
[5,    60] loss: 2.12376
[5,    70] loss: 2.06842
[5,    80] loss: 2.06122
[5,    90] loss: 2.12486
[5,   100] loss: 2.12085
[5,   110] loss: 2.11152
[5,   120] loss: 2.10011
[5,   130] loss: 2.08381
[5,   140] loss: 2.09998
[5,   150] loss: 2.11709
[5,   160] loss: 2.08204
[5,   170] loss: 2.10555
[5,   180] loss: 2.11852
[5,   190] loss: 2.08647
[5,   200] loss: 2.09304
[5,   210] loss: 2.09504
[5,   220] loss: 2.12876
[5,   230] loss: 2.08004
[5,   240] loss: 2.11237
[5,   250] loss: 2.12026
[5,   260] loss: 2.10498
[5,   270] loss: 2.12444
[5,   280] loss: 2.11882
[5,   290] loss: 2.15215
[5,   300] loss: 2.08484
[5,   310] loss: 2.11433
[5,   320] loss: 2.15423
[5,   330] loss: 2.13037
[5,   340] loss: 2.11414
[5,   350] loss: 2.07956
[5,   360] loss: 2.06363
[5,   370] loss: 2.10442
[5,   380] loss: 2.09073
[5,   390] loss: 2.06673
--> Accuracy after epoch 4: 23 %
Epoch 5: lr = 0.005000
[6,    10] loss: 2.04235
[6,    20] loss: 2.12100
[6,    30] loss: 2.16285
[6,    40] loss: 2.06614
[6,    50] loss: 2.03613
[6,    60] loss: 2.14013
[6,    70] loss: 2.12607
[6,    80] loss: 2.09977
[6,    90] loss: 2.08915
[6,   100] loss: 2.09232
[6,   110] loss: 2.14055
[6,   120] loss: 2.09070
[6,   130] loss: 2.08447
[6,   140] loss: 2.11771
[6,   150] loss: 2.07377
[6,   160] loss: 2.06874
[6,   170] loss: 2.06054
[6,   180] loss: 2.06834
[6,   190] loss: 2.04602
[6,   200] loss: 2.09201
[6,   210] loss: 2.13893
[6,   220] loss: 2.11313
[6,   230] loss: 2.09393
[6,   240] loss: 2.16843
[6,   250] loss: 2.10518
[6,   260] loss: 2.13138
[6,   270] loss: 2.10062
[6,   280] loss: 2.14540
[6,   290] loss: 2.12468
[6,   300] loss: 2.13270
[6,   310] loss: 2.12590
[6,   320] loss: 2.09236
[6,   330] loss: 2.08334
[6,   340] loss: 2.15334
[6,   350] loss: 2.15619
[6,   360] loss: 2.12264
[6,   370] loss: 2.14802
[6,   380] loss: 2.14034
[6,   390] loss: 2.08183
--> Accuracy after epoch 5: 22 %
Epoch 6: lr = 0.005000
[7,    10] loss: 2.08004
[7,    20] loss: 2.07612
[7,    30] loss: 2.12110
[7,    40] loss: 2.10628
[7,    50] loss: 2.11705
[7,    60] loss: 2.14423
[7,    70] loss: 2.15362
[7,    80] loss: 2.11733
[7,    90] loss: 2.09081
[7,   100] loss: 2.09337
[7,   110] loss: 2.10405
[7,   120] loss: 2.04681
[7,   130] loss: 2.13688
[7,   140] loss: 2.07313
[7,   150] loss: 2.05697
[7,   160] loss: 2.07711
[7,   170] loss: 2.10756
[7,   180] loss: 2.12664
[7,   190] loss: 2.11271
[7,   200] loss: 2.08135
[7,   210] loss: 2.09610
[7,   220] loss: 2.09305
[7,   230] loss: 2.15046
[7,   240] loss: 2.08973
[7,   250] loss: 2.08049
[7,   260] loss: 2.12165
[7,   270] loss: 2.11773
[7,   280] loss: 2.09113
[7,   290] loss: 2.04718
[7,   300] loss: 2.12525
[7,   310] loss: 2.12512
[7,   320] loss: 2.07273
[7,   330] loss: 2.07778
[7,   340] loss: 2.03034
[7,   350] loss: 2.03879
[7,   360] loss: 2.09925
[7,   370] loss: 2.11419
[7,   380] loss: 2.08080
[7,   390] loss: 2.04502
--> Accuracy after epoch 6: 22 %
Epoch 7: lr = 0.005000
[8,    10] loss: 2.04897
[8,    20] loss: 2.02342
[8,    30] loss: 2.01117
[8,    40] loss: 2.04605
[8,    50] loss: 2.06001
[8,    60] loss: 2.00959
[8,    70] loss: 2.03681
[8,    80] loss: 2.07932
[8,    90] loss: 2.09640
[8,   100] loss: 2.08780
[8,   110] loss: 2.06130
[8,   120] loss: 2.05170
[8,   130] loss: 2.05169
[8,   140] loss: 2.02268
[8,   150] loss: 2.01065
[8,   160] loss: 1.99149
[8,   170] loss: 2.02192
[8,   180] loss: 2.04410
[8,   190] loss: 2.00859
[8,   200] loss: 2.01801
[8,   210] loss: 2.01387
[8,   220] loss: 2.02342
[8,   230] loss: 2.01735
[8,   240] loss: 1.95481
[8,   250] loss: 2.05475
[8,   260] loss: 1.94976
[8,   270] loss: 1.96620
[8,   280] loss: 2.01692
[8,   290] loss: 2.06652
[8,   300] loss: 2.00645
[8,   310] loss: 2.06675
[8,   320] loss: 2.07690
[8,   330] loss: 2.06501
[8,   340] loss: 2.09078
[8,   350] loss: 2.02798
[8,   360] loss: 2.05028
[8,   370] loss: 2.04519
[8,   380] loss: 2.00172
[8,   390] loss: 1.94490
--> Accuracy after epoch 7: 29 %
Epoch 8: lr = 0.005000
[9,    10] loss: 1.99715
[9,    20] loss: 2.08351
[9,    30] loss: 2.08698
[9,    40] loss: 2.06244
[9,    50] loss: 1.98704
[9,    60] loss: 2.00869
[9,    70] loss: 2.06711
[9,    80] loss: 2.06054
[9,    90] loss: 2.08624
[9,   100] loss: 2.13284
[9,   110] loss: 2.14692
[9,   120] loss: 2.13777
[9,   130] loss: 2.11752
[9,   140] loss: 2.12744
[9,   150] loss: 2.15294
[9,   160] loss: 2.16214
[9,   170] loss: 2.14333
[9,   180] loss: 2.15062
[9,   190] loss: 2.14502
[9,   200] loss: 2.14606
[9,   210] loss: 2.11341
[9,   220] loss: 2.12985
[9,   230] loss: 2.13455
[9,   240] loss: 2.14168
[9,   250] loss: 2.12322
[9,   260] loss: 2.13796
[9,   270] loss: 2.12083
[9,   280] loss: 2.12013
[9,   290] loss: 2.10257
[9,   300] loss: 2.18698
[9,   310] loss: 2.09608
[9,   320] loss: 2.15064
[9,   330] loss: 2.16471
[9,   340] loss: 2.14761
[9,   350] loss: 2.10573
[9,   360] loss: 2.11416
[9,   370] loss: 2.13023
[9,   380] loss: 2.19159
[9,   390] loss: 2.10419
--> Accuracy after epoch 8: 13 %
Epoch 9: lr = 0.005000
[10,    10] loss: 2.15243
[10,    20] loss: 2.12059
[10,    30] loss: 2.15240
[10,    40] loss: 2.13880
[10,    50] loss: 2.13167
[10,    60] loss: 2.13446
[10,    70] loss: 2.10764
[10,    80] loss: 2.14114
[10,    90] loss: 2.17292
[10,   100] loss: 2.15564
[10,   110] loss: 2.11790
[10,   120] loss: 2.13221
[10,   130] loss: 2.17308
[10,   140] loss: 2.09897
[10,   150] loss: 2.13276
[10,   160] loss: 2.18158
[10,   170] loss: 2.16911
[10,   180] loss: 2.11032
[10,   190] loss: 2.14256
[10,   200] loss: 2.09597
[10,   210] loss: 2.11975
[10,   220] loss: 2.10999
[10,   230] loss: 2.13462
[10,   240] loss: 2.14084
[10,   250] loss: 2.13308
[10,   260] loss: 2.14411
[10,   270] loss: 2.10590
[10,   280] loss: 2.14352
[10,   290] loss: 2.22589
[10,   300] loss: 2.12499
[10,   310] loss: 2.07572
[10,   320] loss: 2.11503
[10,   330] loss: 2.12882
[10,   340] loss: 2.14130
[10,   350] loss: 2.19792
[10,   360] loss: 2.15652
[10,   370] loss: 2.12731
[10,   380] loss: 2.13506
[10,   390] loss: 2.17490
--> Accuracy after epoch 9: 17 %
Epoch 10: lr = 0.002500
[11,    10] loss: 2.16334
[11,    20] loss: 2.16268
[11,    30] loss: 2.17092
[11,    40] loss: 2.18054
[11,    50] loss: 2.13265
[11,    60] loss: 2.14222
[11,    70] loss: 2.17258
[11,    80] loss: 2.16625
[11,    90] loss: 2.16880
[11,   100] loss: 2.11663
[11,   110] loss: 2.16401
[11,   120] loss: 2.15910
[11,   130] loss: 2.14462
[11,   140] loss: 2.08684
[11,   150] loss: 2.16036
[11,   160] loss: 2.10633
[11,   170] loss: 2.13259
[11,   180] loss: 2.16347
[11,   190] loss: 2.12113
[11,   200] loss: 2.18238
[11,   210] loss: 2.18085
[11,   220] loss: 2.17521
[11,   230] loss: 2.18556
[11,   240] loss: 2.17534
[11,   250] loss: 2.11874
[11,   260] loss: 2.14536
[11,   270] loss: 2.10989
[11,   280] loss: 2.23202
[11,   290] loss: 2.20342
[11,   300] loss: 2.17437
[11,   310] loss: 2.07237
[11,   320] loss: 2.12811
[11,   330] loss: 2.11946
[11,   340] loss: 2.17594
[11,   350] loss: 2.19574
[11,   360] loss: 2.16043
[11,   370] loss: 2.18295
[11,   380] loss: 2.16884
[11,   390] loss: 2.13594
--> Accuracy after epoch 10: 17 %
Epoch 11: lr = 0.002500
[12,    10] loss: 2.12219
[12,    20] loss: 2.14148
[12,    30] loss: 2.15498
[12,    40] loss: 2.10607
[12,    50] loss: 2.14013
[12,    60] loss: 2.10221
[12,    70] loss: 2.21973
[12,    80] loss: 2.09410
[12,    90] loss: 2.15638
[12,   100] loss: 2.12559
[12,   110] loss: 2.14368
[12,   120] loss: 2.16135
[12,   130] loss: 2.17151
[12,   140] loss: 2.17948
[12,   150] loss: 2.18245
[12,   160] loss: 2.18833
[12,   170] loss: 2.18398
[12,   180] loss: 2.17654
[12,   190] loss: 2.18832
[12,   200] loss: 2.21135
[12,   210] loss: 2.17264
[12,   220] loss: 2.14297
[12,   230] loss: 2.14787
[12,   240] loss: 2.16131
[12,   250] loss: 2.14285
[12,   260] loss: 2.16898
[12,   270] loss: 2.15518
[12,   280] loss: 2.19247
[12,   290] loss: 2.14439
[12,   300] loss: 2.15606
[12,   310] loss: 2.13358
[12,   320] loss: 2.08817
[12,   330] loss: 2.14375
[12,   340] loss: 2.14412
[12,   350] loss: 2.13374
[12,   360] loss: 2.11015
[12,   370] loss: 2.17537
[12,   380] loss: 2.15032
[12,   390] loss: 2.14166
--> Accuracy after epoch 11: 19 %
Epoch 12: lr = 0.002500
[13,    10] loss: 2.10148
[13,    20] loss: 2.19497
[13,    30] loss: 2.13445
[13,    40] loss: 2.16550
[13,    50] loss: 2.16621
[13,    60] loss: 2.14176
[13,    70] loss: 2.17437
[13,    80] loss: 2.13780
[13,    90] loss: 2.13636
[13,   100] loss: 2.13561
[13,   110] loss: 2.06284
[13,   120] loss: 2.10080
[13,   130] loss: 2.12561
[13,   140] loss: 2.08874
[13,   150] loss: 2.11482
[13,   160] loss: 2.10713
[13,   170] loss: 2.11906
[13,   180] loss: 2.14453
[13,   190] loss: 2.09922
[13,   200] loss: 2.13864
[13,   210] loss: 2.13486
[13,   220] loss: 2.16668
[13,   230] loss: 2.11349
[13,   240] loss: 2.15651
[13,   250] loss: 2.09624
[13,   260] loss: 2.14301
[13,   270] loss: 2.09058
[13,   280] loss: 2.09758
[13,   290] loss: 2.10635
[13,   300] loss: 2.08165
[13,   310] loss: 2.09502
[13,   320] loss: 2.10748
[13,   330] loss: 2.09996
[13,   340] loss: 2.11292
[13,   350] loss: 2.12422
[13,   360] loss: 2.10998
[13,   370] loss: 2.09225
[13,   380] loss: 2.10379
[13,   390] loss: 2.13776
--> Accuracy after epoch 12: 19 %
Epoch 13: lr = 0.002500
[14,    10] loss: 2.12914
[14,    20] loss: 2.12798
[14,    30] loss: 2.09499
[14,    40] loss: 2.12700
[14,    50] loss: 2.12805
[14,    60] loss: 2.13034
[14,    70] loss: 2.08447
[14,    80] loss: 2.13484
[14,    90] loss: 2.13301
[14,   100] loss: 2.13638
[14,   110] loss: 2.12295
[14,   120] loss: 2.06564
[14,   130] loss: 2.04796
[14,   140] loss: 2.11420
[14,   150] loss: 2.09946
[14,   160] loss: 2.13789
[14,   170] loss: 2.07514
[14,   180] loss: 2.12091
[14,   190] loss: 2.10238
[14,   200] loss: 2.08351
[14,   210] loss: 2.13093
[14,   220] loss: 2.09921
[14,   230] loss: 2.06690
[14,   240] loss: 2.08896
[14,   250] loss: 2.08631
[14,   260] loss: 2.10730
[14,   270] loss: 2.12843
[14,   280] loss: 2.14359
[14,   290] loss: 2.11800
[14,   300] loss: 2.07566
[14,   310] loss: 2.11495
[14,   320] loss: 2.10182
[14,   330] loss: 2.10369
[14,   340] loss: 2.13825
[14,   350] loss: 2.12238
[14,   360] loss: 2.13795
[14,   370] loss: 2.15148
[14,   380] loss: 2.14441
[14,   390] loss: 2.11295
--> Accuracy after epoch 13: 16 %
Epoch 14: lr = 0.002500
[15,    10] loss: 2.12657
[15,    20] loss: 2.09392
[15,    30] loss: 2.11391
[15,    40] loss: 2.13583
[15,    50] loss: 2.12206
[15,    60] loss: 2.07130
[15,    70] loss: 2.08516
[15,    80] loss: 2.12617
[15,    90] loss: 2.14058
[15,   100] loss: 2.03189
[15,   110] loss: 2.10966
[15,   120] loss: 2.04578
[15,   130] loss: 2.07277
[15,   140] loss: 2.09745
[15,   150] loss: 2.09219
[15,   160] loss: 2.06511
[15,   170] loss: 2.06332
[15,   180] loss: 2.09336
[15,   190] loss: 2.04875
[15,   200] loss: 2.09337
[15,   210] loss: 2.11630
[15,   220] loss: 2.06861
[15,   230] loss: 2.11401
[15,   240] loss: 2.12702
[15,   250] loss: 2.04025
[15,   260] loss: 2.05084
[15,   270] loss: 2.07248
[15,   280] loss: 2.13439
[15,   290] loss: 2.02979
[15,   300] loss: 2.05868
[15,   310] loss: 2.12985
[15,   320] loss: 2.09130
[15,   330] loss: 2.10749
[15,   340] loss: 2.13334
[15,   350] loss: 2.11009
[15,   360] loss: 2.10760
[15,   370] loss: 2.14240
[15,   380] loss: 2.16200
[15,   390] loss: 2.11897
--> Accuracy after epoch 14: 20 %
Epoch 15: lr = 0.002500
[16,    10] loss: 2.13618
[16,    20] loss: 2.15757
[16,    30] loss: 2.10784
[16,    40] loss: 2.11903
[16,    50] loss: 2.14149
[16,    60] loss: 2.10808
[16,    70] loss: 2.07854
[16,    80] loss: 2.08445
[16,    90] loss: 2.15425
[16,   100] loss: 2.15001
[16,   110] loss: 2.13802
[16,   120] loss: 2.12193
[16,   130] loss: 2.08718
[16,   140] loss: 2.10362
[16,   150] loss: 2.15784
[16,   160] loss: 2.14852
[16,   170] loss: 2.07435
[16,   180] loss: 2.06683
[16,   190] loss: 2.13596
[16,   200] loss: 2.21334
[16,   210] loss: 2.14218
[16,   220] loss: 2.11870
[16,   230] loss: 2.07950
[16,   240] loss: 2.16735
[16,   250] loss: 2.11387
[16,   260] loss: 2.18588
[16,   270] loss: 2.14485
[16,   280] loss: 2.14789
[16,   290] loss: 2.15557
[16,   300] loss: 2.15220
[16,   310] loss: 2.14828
[16,   320] loss: 2.15894
[16,   330] loss: 2.13918
[16,   340] loss: 2.11985
[16,   350] loss: 2.16077
[16,   360] loss: 2.16388
[16,   370] loss: 2.17186
[16,   380] loss: 2.12580
[16,   390] loss: 2.16688
--> Accuracy after epoch 15: 15 %
Epoch 16: lr = 0.002500
[17,    10] loss: 2.18392
[17,    20] loss: 2.11929
[17,    30] loss: 2.13882
[17,    40] loss: 2.10336
[17,    50] loss: 2.16038
[17,    60] loss: 2.15415
[17,    70] loss: 2.16036
[17,    80] loss: 2.20917
[17,    90] loss: 2.13630
[17,   100] loss: 2.18584
[17,   110] loss: 2.15558
[17,   120] loss: 2.13110
[17,   130] loss: 2.13595
[17,   140] loss: 2.18192
[17,   150] loss: 2.10376
[17,   160] loss: 2.12241
[17,   170] loss: 2.17711
[17,   180] loss: 2.13708
[17,   190] loss: 2.15448
[17,   200] loss: 2.21388
[17,   210] loss: 2.23779
[17,   220] loss: 2.21411
[17,   230] loss: 2.11429
[17,   240] loss: 2.15339
[17,   250] loss: 2.11294
[17,   260] loss: 2.12964
[17,   270] loss: 2.10402
[17,   280] loss: 2.18321
[17,   290] loss: 2.14446
[17,   300] loss: 2.19117
[17,   310] loss: 2.13600
[17,   320] loss: 2.21854
[17,   330] loss: 2.21222
[17,   340] loss: 2.13492
[17,   350] loss: 2.13453
[17,   360] loss: 2.10408
[17,   370] loss: 2.14180
[17,   380] loss: 2.19107
[17,   390] loss: 2.17355
--> Accuracy after epoch 16: 13 %
Epoch 17: lr = 0.002500
[18,    10] loss: 2.17956
[18,    20] loss: 2.21104
[18,    30] loss: 2.11032
[18,    40] loss: 2.17575
[18,    50] loss: 2.14533
[18,    60] loss: 2.16346
[18,    70] loss: 2.23643
[18,    80] loss: 2.14983
[18,    90] loss: 2.15176
[18,   100] loss: 2.15898
[18,   110] loss: 2.17956
[18,   120] loss: 2.17852
[18,   130] loss: 2.20804
[18,   140] loss: 2.17456
[18,   150] loss: 2.14172
[18,   160] loss: 2.15519
[18,   170] loss: 2.17107
[18,   180] loss: 2.15575
[18,   190] loss: 2.13929
[18,   200] loss: 2.18393
[18,   210] loss: 2.14475
[18,   220] loss: 2.13248
[18,   230] loss: 2.18447
[18,   240] loss: 2.16367
[18,   250] loss: 2.15942
[18,   260] loss: 2.17680
[18,   270] loss: 2.16987
[18,   280] loss: 2.21946
[18,   290] loss: 2.21810
[18,   300] loss: 2.15804
[18,   310] loss: 2.14022
[18,   320] loss: 2.13651
[18,   330] loss: 2.16764
[18,   340] loss: 2.16902
[18,   350] loss: 2.12449
[18,   360] loss: 2.11878
[18,   370] loss: 2.19053
[18,   380] loss: 2.12636
[18,   390] loss: 2.17072
--> Accuracy after epoch 17: 18 %
Epoch 18: lr = 0.002500
[19,    10] loss: 2.17362
[19,    20] loss: 2.18297
[19,    30] loss: 2.13505
[19,    40] loss: 2.16454
[19,    50] loss: 2.21535
[19,    60] loss: 2.21398
[19,    70] loss: 2.19203
[19,    80] loss: 2.21148
[19,    90] loss: 2.19044
[19,   100] loss: 2.24855
[19,   110] loss: 2.28378
[19,   120] loss: 2.29632
[19,   130] loss: 2.29252
[19,   140] loss: 2.28559
[19,   150] loss: 2.28385
[19,   160] loss: 2.29295
[19,   170] loss: 2.28928
[19,   180] loss: 2.28544
[19,   190] loss: 2.28924
[19,   200] loss: 2.28831
[19,   210] loss: 2.28279
[19,   220] loss: 2.28660
[19,   230] loss: 2.28862
[19,   240] loss: 2.28112
[19,   250] loss: 2.28503
[19,   260] loss: 2.27982
[19,   270] loss: 2.29420
[19,   280] loss: 2.28135
[19,   290] loss: 2.27538
[19,   300] loss: 2.28576
[19,   310] loss: 2.28219
[19,   320] loss: 2.27502
[19,   330] loss: 2.28777
[19,   340] loss: 2.27825
[19,   350] loss: 2.28641
[19,   360] loss: 2.28305
[19,   370] loss: 2.27171
[19,   380] loss: 2.28511
[19,   390] loss: 2.28835
--> Accuracy after epoch 18: 14 %
Epoch 19: lr = 0.002500
[20,    10] loss: 2.27973
[20,    20] loss: 2.27458
[20,    30] loss: 2.26357
[20,    40] loss: 2.28591
[20,    50] loss: 2.27055
[20,    60] loss: 2.27804
[20,    70] loss: 2.27380
[20,    80] loss: 2.26550
[20,    90] loss: 2.28064
[20,   100] loss: 2.27593
[20,   110] loss: 2.27501
[20,   120] loss: 2.28155
[20,   130] loss: 2.26290
[20,   140] loss: 2.28256
[20,   150] loss: 2.28001
[20,   160] loss: 2.25873
[20,   170] loss: 2.27568
[20,   180] loss: 2.28186
[20,   190] loss: 2.29101
[20,   200] loss: 2.27964
[20,   210] loss: 2.26069
[20,   220] loss: 2.27263
[20,   230] loss: 2.28438
[20,   240] loss: 2.28351
[20,   250] loss: 2.26913
[20,   260] loss: 2.27458
[20,   270] loss: 2.26185
[20,   280] loss: 2.26861
[20,   290] loss: 2.27643
[20,   300] loss: 2.26815
[20,   310] loss: 2.26854
[20,   320] loss: 2.27848
[20,   330] loss: 2.27373
[20,   340] loss: 2.27191
[20,   350] loss: 2.27879
[20,   360] loss: 2.26889
[20,   370] loss: 2.26713
[20,   380] loss: 2.26237
[20,   390] loss: 2.26674
--> Accuracy after epoch 19: 15 %
Epoch 20: lr = 0.001250
[21,    10] loss: 2.26789
[21,    20] loss: 2.27625
[21,    30] loss: 2.27529
[21,    40] loss: 2.27884
[21,    50] loss: 2.26289
[21,    60] loss: 2.26988
[21,    70] loss: 2.27241
[21,    80] loss: 2.25549
[21,    90] loss: 2.27984
[21,   100] loss: 2.25593
[21,   110] loss: 2.27546
[21,   120] loss: 2.26473
[21,   130] loss: 2.26508
[21,   140] loss: 2.26519
[21,   150] loss: 2.25838
[21,   160] loss: 2.25856
[21,   170] loss: 2.25749
[21,   180] loss: 2.26899
[21,   190] loss: 2.27517
[21,   200] loss: 2.28051
[21,   210] loss: 2.26653
[21,   220] loss: 2.26589
[21,   230] loss: 2.25094
[21,   240] loss: 2.28267
[21,   250] loss: 2.26257
[21,   260] loss: 2.26559
[21,   270] loss: 2.26842
[21,   280] loss: 2.26487
[21,   290] loss: 2.27574
[21,   300] loss: 2.27087
[21,   310] loss: 2.27523
[21,   320] loss: 2.27584
[21,   330] loss: 2.27063
[21,   340] loss: 2.27223
[21,   350] loss: 2.27525
[21,   360] loss: 2.27285
[21,   370] loss: 2.27710
[21,   380] loss: 2.27459
[21,   390] loss: 2.28490
--> Accuracy after epoch 20: 13 %
Epoch 21: lr = 0.001250
[22,    10] loss: 2.27355
[22,    20] loss: 2.27214
[22,    30] loss: 2.27668
[22,    40] loss: 2.28810
[22,    50] loss: 2.28063
[22,    60] loss: 2.26702
[22,    70] loss: 2.27992
[22,    80] loss: 2.27751
[22,    90] loss: 2.28071
[22,   100] loss: 2.29144
[22,   110] loss: 2.28189
[22,   120] loss: 2.27656
[22,   130] loss: 2.29421
[22,   140] loss: 2.29215
[22,   150] loss: 2.28127
[22,   160] loss: 2.29328
[22,   170] loss: 2.27762
[22,   180] loss: 2.29762
[22,   190] loss: 2.28239
[22,   200] loss: 2.28241
[22,   210] loss: 2.28999
[22,   220] loss: 2.29471
[22,   230] loss: 2.28669
[22,   240] loss: 2.28795
[22,   250] loss: 2.29699
[22,   260] loss: 2.29299
[22,   270] loss: 2.29574
[22,   280] loss: 2.28277
[22,   290] loss: 2.29377
[22,   300] loss: 2.29832
[22,   310] loss: 2.28681
[22,   320] loss: 2.29054
[22,   330] loss: 2.29240
[22,   340] loss: 2.29757
[22,   350] loss: 2.29368
[22,   360] loss: 2.29727
[22,   370] loss: 2.29671
[22,   380] loss: 2.30107
[22,   390] loss: 2.29432
--> Accuracy after epoch 21: 10 %
Epoch 22: lr = 0.001250
[23,    10] loss: 2.30088
[23,    20] loss: 2.29773
[23,    30] loss: 2.30408
[23,    40] loss: 2.30104
[23,    50] loss: 2.30150
[23,    60] loss: 2.29859
[23,    70] loss: 2.30765
[23,    80] loss: 2.30275
[23,    90] loss: 2.29850
[23,   100] loss: 2.30171
[23,   110] loss: 2.30253
[23,   120] loss: 2.30173
[23,   130] loss: 2.29805
[23,   140] loss: 2.30378
[23,   150] loss: 2.30196
[23,   160] loss: 2.30275
[23,   170] loss: 2.30201
[23,   180] loss: 2.29456
[23,   190] loss: 2.30028
[23,   200] loss: 2.30310
[23,   210] loss: 2.30436
[23,   220] loss: 2.30344
[23,   230] loss: 2.30236
[23,   240] loss: 2.29955
[23,   250] loss: 2.30380
[23,   260] loss: 2.30098
[23,   270] loss: 2.30183
[23,   280] loss: 2.30702
[23,   290] loss: 2.30393
[23,   300] loss: 2.30015
[23,   310] loss: 2.30462
[23,   320] loss: 2.30177
[23,   330] loss: 2.30252
[23,   340] loss: 2.30534
[23,   350] loss: 2.30536
[23,   360] loss: 2.30254
[23,   370] loss: 2.30258
[23,   380] loss: 2.30329
[23,   390] loss: 2.30255
--> Accuracy after epoch 22: 10 %
Epoch 23: lr = 0.001250
[24,    10] loss: 2.30329
[24,    20] loss: 2.30330
[24,    30] loss: 2.30330
[24,    40] loss: 2.30402
[24,    50] loss: 2.30113
[24,    60] loss: 2.30620
[24,    70] loss: 2.30403
[24,    80] loss: 2.30186
[24,    90] loss: 2.30511
[24,   100] loss: 2.30186
[24,   110] loss: 2.30258
[24,   120] loss: 2.30332
[24,   130] loss: 2.30332
[24,   140] loss: 2.30258
[24,   150] loss: 2.30333
[24,   160] loss: 2.30258
[24,   170] loss: 2.30634
[24,   180] loss: 2.30484
[24,   190] loss: 2.30187
[24,   200] loss: 2.30334
[24,   210] loss: 2.30258
[24,   220] loss: 2.30258
[24,   230] loss: 2.30335
[24,   240] loss: 2.30258
[24,   250] loss: 2.30565
[24,   260] loss: 2.30258
[24,   270] loss: 2.30258
[24,   280] loss: 2.30258
[24,   290] loss: 2.30258
[24,   300] loss: 2.30258
[24,   310] loss: 2.30336
[24,   320] loss: 2.30258
[24,   330] loss: 2.30258
[24,   340] loss: 2.30258
[24,   350] loss: 2.30258
[24,   360] loss: 2.30258
[24,   370] loss: 2.30258
[24,   380] loss: 2.30258
[24,   390] loss: 2.30258
--> Accuracy after epoch 23: 10 %
Epoch 24: lr = 0.001250
[25,    10] loss: 2.30338
[25,    20] loss: 2.30258
[25,    30] loss: 2.30258
[25,    40] loss: 2.30339
[25,    50] loss: 2.30258
[25,    60] loss: 2.30339
[25,    70] loss: 2.30339
[25,    80] loss: 2.30258
[25,    90] loss: 2.30258
[25,   100] loss: 2.30258
[25,   110] loss: 2.30258
[25,   120] loss: 2.30258
[25,   130] loss: 2.30340
[25,   140] loss: 2.30258
[25,   150] loss: 2.30258
[25,   160] loss: 2.30258
[25,   170] loss: 2.30258
[25,   180] loss: 2.30258
[25,   190] loss: 2.30258
[25,   200] loss: 2.30258
[25,   210] loss: 2.30258
[25,   220] loss: 2.30258
[25,   230] loss: 2.30258
[25,   240] loss: 2.30258
[25,   250] loss: 2.30258
[25,   260] loss: 2.30258
[25,   270] loss: 2.30258
[25,   280] loss: 2.30258
[25,   290] loss: 2.30258
[25,   300] loss: 2.30258
[25,   310] loss: 2.30258
[25,   320] loss: 2.30258
[25,   330] loss: 2.30258
[25,   340] loss: 2.30258
[25,   350] loss: 2.30258
[25,   360] loss: 2.30258
[25,   370] loss: 2.30258
[25,   380] loss: 2.30258
[25,   390] loss: 2.30258
--> Accuracy after epoch 24: 10 %
Finished Training
Accuracy of the network on the 10000 test images: 10 %
Saving data to mat file...
done!
