Pytorch version:
0.2.0_2
Output name: out_1_0.01_1_0.8
Outputting debug data to: out_1_0.01_1_0.8.txt
Outputting matlab data to: out_1_0.01_1_0.8.mat
Subspace projection ON
Noisy test set OFF
Epoch 0: lr = 0.010000
[1,    10] loss: 2.28483
[1,    20] loss: 2.17854
[1,    30] loss: 2.05909
[1,    40] loss: 2.04478
[1,    50] loss: 2.02760
[1,    60] loss: 2.02784
[1,    70] loss: 2.06493
[1,    80] loss: 2.01108
[1,    90] loss: 1.93878
[1,   100] loss: 1.98349
[1,   110] loss: 1.93545
[1,   120] loss: 1.92441
[1,   130] loss: 1.93285
[1,   140] loss: 1.96397
[1,   150] loss: 1.94144
[1,   160] loss: 1.92329
[1,   170] loss: 1.87386
[1,   180] loss: 1.87078
[1,   190] loss: 1.91040
[1,   200] loss: 1.89157
[1,   210] loss: 1.85362
[1,   220] loss: 1.98921
[1,   230] loss: 1.87193
[1,   240] loss: 1.84536
[1,   250] loss: 1.83218
[1,   260] loss: 1.87042
[1,   270] loss: 1.82288
[1,   280] loss: 1.84581
[1,   290] loss: 1.87521
[1,   300] loss: 1.83205
[1,   310] loss: 1.87578
[1,   320] loss: 1.76135
[1,   330] loss: 1.87618
[1,   340] loss: 1.91745
[1,   350] loss: 1.82868
[1,   360] loss: 1.78239
[1,   370] loss: 1.88835
[1,   380] loss: 1.77307
[1,   390] loss: 1.76462
--> Accuracy after epoch 0: 42 %
Epoch 1: lr = 0.010000
[2,    10] loss: 1.77983
[2,    20] loss: 1.86187
[2,    30] loss: 1.80855
[2,    40] loss: 1.76205
[2,    50] loss: 1.81190
[2,    60] loss: 1.73701
[2,    70] loss: 1.81810
[2,    80] loss: 1.74393
[2,    90] loss: 1.77582
[2,   100] loss: 1.77462
[2,   110] loss: 1.82140
[2,   120] loss: 1.74574
[2,   130] loss: 1.80764
[2,   140] loss: 1.74664
[2,   150] loss: 1.76995
[2,   160] loss: 1.81956
[2,   170] loss: 1.75358
[2,   180] loss: 1.73296
[2,   190] loss: 1.76403
[2,   200] loss: 1.71529
[2,   210] loss: 1.73515
[2,   220] loss: 1.76063
[2,   230] loss: 1.73471
[2,   240] loss: 1.75735
[2,   250] loss: 1.68255
[2,   260] loss: 1.77771
[2,   270] loss: 1.69973
[2,   280] loss: 1.73281
[2,   290] loss: 1.72229
[2,   300] loss: 1.67870
[2,   310] loss: 1.68800
[2,   320] loss: 1.78106
[2,   330] loss: 1.70273
[2,   340] loss: 1.69216
[2,   350] loss: 1.75451
[2,   360] loss: 1.76749
[2,   370] loss: 1.75338
[2,   380] loss: 1.72177
[2,   390] loss: 1.68153
--> Accuracy after epoch 1: 46 %
Epoch 2: lr = 0.010000
[3,    10] loss: 1.68834
[3,    20] loss: 1.68179
[3,    30] loss: 1.69411
[3,    40] loss: 1.73913
[3,    50] loss: 1.80569
[3,    60] loss: 1.75912
[3,    70] loss: 1.79714
[3,    80] loss: 1.75618
[3,    90] loss: 1.79940
[3,   100] loss: 1.75424
[3,   110] loss: 1.77473
[3,   120] loss: 1.76002
[3,   130] loss: 1.77618
[3,   140] loss: 1.80446
[3,   150] loss: 1.80288
[3,   160] loss: 1.70014
[3,   170] loss: 1.73968
[3,   180] loss: 1.70651
[3,   190] loss: 1.75460
[3,   200] loss: 1.77505
[3,   210] loss: 1.85775
[3,   220] loss: 1.85271
[3,   230] loss: 1.83546
[3,   240] loss: 1.78026
[3,   250] loss: 1.79220
[3,   260] loss: 1.78247
[3,   270] loss: 1.83672
[3,   280] loss: 1.69217
[3,   290] loss: 1.71192
[3,   300] loss: 1.73012
[3,   310] loss: 1.82391
[3,   320] loss: 1.71506
[3,   330] loss: 1.70066
[3,   340] loss: 1.77976
[3,   350] loss: 1.76835
[3,   360] loss: 1.71525
[3,   370] loss: 1.70167
[3,   380] loss: 1.69910
[3,   390] loss: 1.77403
--> Accuracy after epoch 2: 42 %
Epoch 3: lr = 0.010000
[4,    10] loss: 1.74133
[4,    20] loss: 1.73098
[4,    30] loss: 1.69478
[4,    40] loss: 1.71693
[4,    50] loss: 1.76214
[4,    60] loss: 1.85230
[4,    70] loss: 1.86339
[4,    80] loss: 1.85341
[4,    90] loss: 1.84117
[4,   100] loss: 1.90215
[4,   110] loss: 1.80809
[4,   120] loss: 1.81127
[4,   130] loss: 1.85288
[4,   140] loss: 1.88420
[4,   150] loss: 1.86698
[4,   160] loss: 1.94708
[4,   170] loss: 1.95573
[4,   180] loss: 1.95034
[4,   190] loss: 1.88751
[4,   200] loss: 1.87860
[4,   210] loss: 1.91174
[4,   220] loss: 1.88598
[4,   230] loss: 1.88032
[4,   240] loss: 1.91174
[4,   250] loss: 1.90633
[4,   260] loss: 1.97723
[4,   270] loss: 2.03324
[4,   280] loss: 1.94740
[4,   290] loss: 1.83024
[4,   300] loss: 1.91030
[4,   310] loss: 1.92404
[4,   320] loss: 1.92595
[4,   330] loss: 1.94407
[4,   340] loss: 1.94871
[4,   350] loss: 1.97278
[4,   360] loss: 1.89199
[4,   370] loss: 1.99345
[4,   380] loss: 1.97403
[4,   390] loss: 1.92654
--> Accuracy after epoch 3: 34 %
Epoch 4: lr = 0.010000
[5,    10] loss: 1.93725
[5,    20] loss: 1.91866
[5,    30] loss: 1.91892
[5,    40] loss: 1.89800
[5,    50] loss: 1.97143
[5,    60] loss: 1.93623
[5,    70] loss: 1.95335
[5,    80] loss: 1.99466
[5,    90] loss: 1.90401
[5,   100] loss: 1.92332
[5,   110] loss: 1.98017
[5,   120] loss: 1.91754
[5,   130] loss: 2.01677
[5,   140] loss: 1.90208
[5,   150] loss: 1.96279
[5,   160] loss: 1.95144
[5,   170] loss: 1.92153
[5,   180] loss: 1.88962
[5,   190] loss: 1.96857
[5,   200] loss: 2.01722
[5,   210] loss: 2.01365
[5,   220] loss: 2.01183
[5,   230] loss: 2.02556
[5,   240] loss: 1.96942
[5,   250] loss: 1.98516
[5,   260] loss: 1.99825
[5,   270] loss: 1.98490
[5,   280] loss: 1.96881
[5,   290] loss: 1.97524
[5,   300] loss: 1.95322
[5,   310] loss: 1.97402
[5,   320] loss: 1.99087
[5,   330] loss: 1.97341
[5,   340] loss: 2.04467
[5,   350] loss: 2.00716
[5,   360] loss: 2.01883
[5,   370] loss: 2.03742
[5,   380] loss: 2.06397
[5,   390] loss: 2.08095
--> Accuracy after epoch 4: 23 %
Epoch 5: lr = 0.010000
[6,    10] loss: 2.04820
[6,    20] loss: 2.07747
[6,    30] loss: 2.10176
[6,    40] loss: 2.01938
[6,    50] loss: 2.10835
[6,    60] loss: 2.15857
[6,    70] loss: 2.00791
[6,    80] loss: 2.12866
[6,    90] loss: 2.06185
[6,   100] loss: 2.03395
[6,   110] loss: 2.07011
[6,   120] loss: 2.11651
[6,   130] loss: 2.07537
[6,   140] loss: 2.08278
[6,   150] loss: 2.06384
[6,   160] loss: 2.03148
[6,   170] loss: 2.02094
[6,   180] loss: 2.06728
[6,   190] loss: 2.03297
[6,   200] loss: 2.17133
[6,   210] loss: 2.20360
[6,   220] loss: 2.20656
[6,   230] loss: 2.23167
[6,   240] loss: 2.22840
[6,   250] loss: 2.22725
[6,   260] loss: 2.31597
[6,   270] loss: 2.25876
[6,   280] loss: 2.20099
[6,   290] loss: 2.15847
[6,   300] loss: 2.18649
[6,   310] loss: 2.29285
[6,   320] loss: 2.20064
[6,   330] loss: 2.17541
[6,   340] loss: 2.22891
[6,   350] loss: 2.28006
[6,   360] loss: 2.24331
[6,   370] loss: 2.24949
[6,   380] loss: 2.31777
[6,   390] loss: 2.21820
--> Accuracy after epoch 5: 17 %
Epoch 6: lr = 0.010000
[7,    10] loss: 2.21508
[7,    20] loss: 2.20743
[7,    30] loss: 2.24520
[7,    40] loss: 2.21147
[7,    50] loss: 2.22242
[7,    60] loss: 2.21289
[7,    70] loss: 2.20597
[7,    80] loss: 2.21823
[7,    90] loss: 2.29956
[7,   100] loss: 2.20512
[7,   110] loss: 2.17095
[7,   120] loss: 2.25104
[7,   130] loss: 2.22335
[7,   140] loss: 2.29875
[7,   150] loss: 2.26192
[7,   160] loss: 2.24179
[7,   170] loss: 2.24381
[7,   180] loss: 2.26374
[7,   190] loss: 2.26999
[7,   200] loss: 2.26533
[7,   210] loss: 2.28630
[7,   220] loss: 2.27223
[7,   230] loss: 2.27648
[7,   240] loss: 2.27887
[7,   250] loss: 2.29114
[7,   260] loss: 2.27921
[7,   270] loss: 2.29631
[7,   280] loss: 2.28548
[7,   290] loss: 2.28309
[7,   300] loss: 2.29966
[7,   310] loss: 2.27594
[7,   320] loss: 2.29432
[7,   330] loss: 2.31685
[7,   340] loss: 2.29172
[7,   350] loss: 2.28994
[7,   360] loss: 2.29233
[7,   370] loss: 2.29886
[7,   380] loss: 2.29582
[7,   390] loss: 2.29510
--> Accuracy after epoch 6: 15 %
Epoch 7: lr = 0.010000
[8,    10] loss: 2.29983
[8,    20] loss: 2.29364
[8,    30] loss: 2.29747
[8,    40] loss: 2.29384
[8,    50] loss: 2.29676
[8,    60] loss: 2.29824
[8,    70] loss: 2.30072
[8,    80] loss: 2.30760
[8,    90] loss: 2.30209
[8,   100] loss: 2.30009
[8,   110] loss: 2.29950
[8,   120] loss: 2.29722
[8,   130] loss: 2.29973
[8,   140] loss: 2.29733
[8,   150] loss: 2.29374
[8,   160] loss: 2.29936
[8,   170] loss: 2.29804
[8,   180] loss: 2.29714
[8,   190] loss: 2.29838
[8,   200] loss: 2.29507
[8,   210] loss: 2.29664
[8,   220] loss: 2.29491
[8,   230] loss: 2.29797
[8,   240] loss: 2.29912
[8,   250] loss: 2.30378
[8,   260] loss: 2.29023
[8,   270] loss: 2.29782
[8,   280] loss: 2.29056
[8,   290] loss: 2.29500
[8,   300] loss: 2.29174
[8,   310] loss: 2.28963
[8,   320] loss: 2.29513
[8,   330] loss: 2.29487
[8,   340] loss: 2.29210
[8,   350] loss: 2.28971
[8,   360] loss: 2.28758
[8,   370] loss: 2.29043
[8,   380] loss: 2.29125
[8,   390] loss: 2.29080
--> Accuracy after epoch 7: 11 %
Epoch 8: lr = 0.010000
[9,    10] loss: 2.28522
[9,    20] loss: 2.29553
[9,    30] loss: 2.29641
[9,    40] loss: 2.28678
[9,    50] loss: 2.28873
[9,    60] loss: 2.29496
[9,    70] loss: 2.28369
[9,    80] loss: 2.29767
[9,    90] loss: 2.29642
[9,   100] loss: 2.28887
[9,   110] loss: 2.28113
[9,   120] loss: 2.28951
[9,   130] loss: 2.28972
[9,   140] loss: 2.28766
[9,   150] loss: 2.28718
[9,   160] loss: 2.28801
[9,   170] loss: 2.28216
[9,   180] loss: 2.28544
[9,   190] loss: 2.28211
[9,   200] loss: 2.28553
[9,   210] loss: 2.28357
[9,   220] loss: 2.27995
[9,   230] loss: 2.27901
[9,   240] loss: 2.29123
[9,   250] loss: 2.28407
[9,   260] loss: 2.27712
[9,   270] loss: 2.29050
[9,   280] loss: 2.28278
[9,   290] loss: 2.28145
[9,   300] loss: 2.28686
[9,   310] loss: 2.29857
[9,   320] loss: 2.27989
[9,   330] loss: 2.28463
[9,   340] loss: 2.27690
[9,   350] loss: 2.27816
[9,   360] loss: 2.27300
[9,   370] loss: 2.26381
[9,   380] loss: 2.25475
[9,   390] loss: 2.26211
--> Accuracy after epoch 8: 11 %
Epoch 9: lr = 0.010000
[10,    10] loss: 2.25459
[10,    20] loss: 2.25194
[10,    30] loss: 2.24694
[10,    40] loss: 2.25850
[10,    50] loss: 2.26375
[10,    60] loss: 2.26983
[10,    70] loss: 2.30290
[10,    80] loss: 2.24704
[10,    90] loss: 2.28413
[10,   100] loss: 2.27817
[10,   110] loss: 2.26118
[10,   120] loss: 2.26012
[10,   130] loss: 2.25580
[10,   140] loss: 2.24580
[10,   150] loss: 2.25000
[10,   160] loss: 2.26484
[10,   170] loss: 2.24594
[10,   180] loss: 2.25686
[10,   190] loss: 2.24064
[10,   200] loss: 2.25358
[10,   210] loss: 2.25035
[10,   220] loss: 2.26327
[10,   230] loss: 2.26471
[10,   240] loss: 2.25757
[10,   250] loss: 2.24984
[10,   260] loss: 2.24503
[10,   270] loss: 2.23953
[10,   280] loss: 2.22821
[10,   290] loss: 2.23805
[10,   300] loss: 2.23814
[10,   310] loss: 2.22567
[10,   320] loss: 2.23150
[10,   330] loss: 2.19624
[10,   340] loss: 2.28213
[10,   350] loss: 2.23671
[10,   360] loss: 2.23919
[10,   370] loss: 2.25452
[10,   380] loss: 2.26746
[10,   390] loss: 2.26590
--> Accuracy after epoch 9: 13 %
Epoch 10: lr = 0.008000
[11,    10] loss: 2.26253
[11,    20] loss: 2.24377
[11,    30] loss: 2.26360
[11,    40] loss: 2.22497
[11,    50] loss: 2.22721
[11,    60] loss: 2.23051
[11,    70] loss: 2.24264
[11,    80] loss: 2.23835
[11,    90] loss: 2.24196
[11,   100] loss: 2.24552
[11,   110] loss: 2.23113
[11,   120] loss: 2.24391
[11,   130] loss: 2.24488
[11,   140] loss: 2.24278
[11,   150] loss: 2.24430
[11,   160] loss: 2.25936
[11,   170] loss: 2.25169
[11,   180] loss: 2.24531
[11,   190] loss: 2.24862
[11,   200] loss: 2.26346
[11,   210] loss: 2.25390
[11,   220] loss: 2.23654
[11,   230] loss: 2.23734
[11,   240] loss: 2.22755
[11,   250] loss: 2.26450
[11,   260] loss: 2.24062
[11,   270] loss: 2.23672
[11,   280] loss: 2.25169
[11,   290] loss: 2.23432
[11,   300] loss: 2.23547
[11,   310] loss: 2.23942
[11,   320] loss: 2.25086
[11,   330] loss: 2.21735
[11,   340] loss: 2.24102
[11,   350] loss: 2.25981
[11,   360] loss: 2.21643
[11,   370] loss: 2.21849
[11,   380] loss: 2.25049
[11,   390] loss: 2.26573
--> Accuracy after epoch 10: 12 %
Epoch 11: lr = 0.008000
[12,    10] loss: 2.23081
[12,    20] loss: 2.25380
[12,    30] loss: 2.22538
[12,    40] loss: 2.24517
[12,    50] loss: 2.24434
[12,    60] loss: 2.24193
[12,    70] loss: 2.24917
[12,    80] loss: 2.22668
[12,    90] loss: 2.22669
[12,   100] loss: 2.22193
[12,   110] loss: 2.21282
[12,   120] loss: 2.25725
[12,   130] loss: 2.26194
[12,   140] loss: 2.23015
[12,   150] loss: 2.25385
[12,   160] loss: 2.20762
[12,   170] loss: 2.22596
[12,   180] loss: 2.20749
[12,   190] loss: 2.21671
[12,   200] loss: 2.25148
[12,   210] loss: 2.23018
[12,   220] loss: 2.23597
[12,   230] loss: 2.21463
[12,   240] loss: 2.22766
[12,   250] loss: 2.20613
[12,   260] loss: 2.22566
[12,   270] loss: 2.22793
[12,   280] loss: 2.22797
[12,   290] loss: 2.23116
[12,   300] loss: 2.23304
[12,   310] loss: 2.23783
[12,   320] loss: 2.22646
[12,   330] loss: 2.22969
[12,   340] loss: 2.22582
[12,   350] loss: 2.24098
[12,   360] loss: 2.21277
[12,   370] loss: 2.22115
[12,   380] loss: 2.19015
[12,   390] loss: 2.22016
--> Accuracy after epoch 11: 15 %
Epoch 12: lr = 0.008000
[13,    10] loss: 2.20290
[13,    20] loss: 2.21598
[13,    30] loss: 2.19999
[13,    40] loss: 2.20768
[13,    50] loss: 2.24092
[13,    60] loss: 2.24178
[13,    70] loss: 2.22938
[13,    80] loss: 2.21302
[13,    90] loss: 2.19247
[13,   100] loss: 2.22349
[13,   110] loss: 2.22732
[13,   120] loss: 2.23689
[13,   130] loss: 2.24014
[13,   140] loss: 2.18892
[13,   150] loss: 2.21940
[13,   160] loss: 2.21626
[13,   170] loss: 2.26028
[13,   180] loss: 2.22998
[13,   190] loss: 2.24575
[13,   200] loss: 2.21235
[13,   210] loss: 2.23646
[13,   220] loss: 2.19169
[13,   230] loss: 2.22415
[13,   240] loss: 2.22212
[13,   250] loss: 2.23562
[13,   260] loss: 2.22772
[13,   270] loss: 2.23872
[13,   280] loss: 2.21801
[13,   290] loss: 2.24979
[13,   300] loss: 2.23910
[13,   310] loss: 2.23945
[13,   320] loss: 2.23466
[13,   330] loss: 2.24807
[13,   340] loss: 2.23913
[13,   350] loss: 2.23610
[13,   360] loss: 2.24072
[13,   370] loss: 2.21536
[13,   380] loss: 2.21419
[13,   390] loss: 2.23628
--> Accuracy after epoch 12: 14 %
Epoch 13: lr = 0.008000
[14,    10] loss: 2.22975
[14,    20] loss: 2.23276
[14,    30] loss: 2.24202
[14,    40] loss: 2.22381
[14,    50] loss: 2.28387
[14,    60] loss: 2.28306
[14,    70] loss: 2.28561
[14,    80] loss: 2.22801
[14,    90] loss: 2.31341
[14,   100] loss: 2.23569
[14,   110] loss: 2.24806
[14,   120] loss: 2.24703
[14,   130] loss: 2.20337
[14,   140] loss: 2.23931
[14,   150] loss: 2.25579
[14,   160] loss: 2.24877
[14,   170] loss: 2.21828
[14,   180] loss: 2.26258
[14,   190] loss: 2.23921
[14,   200] loss: 2.24707
[14,   210] loss: 2.25104
[14,   220] loss: 2.25045
[14,   230] loss: 2.26261
[14,   240] loss: 2.26151
[14,   250] loss: 2.26705
[14,   260] loss: 2.25768
[14,   270] loss: 2.25705
[14,   280] loss: 2.26049
[14,   290] loss: 2.25415
[14,   300] loss: 2.25331
[14,   310] loss: 2.25528
[14,   320] loss: 2.24814
[14,   330] loss: 2.24224
[14,   340] loss: 2.25305
[14,   350] loss: 2.24046
[14,   360] loss: 2.25122
[14,   370] loss: 2.23185
[14,   380] loss: 2.23192
[14,   390] loss: 2.27713
--> Accuracy after epoch 13: 15 %
Epoch 14: lr = 0.008000
[15,    10] loss: 2.26195
[15,    20] loss: 2.27825
[15,    30] loss: 2.27381
[15,    40] loss: 2.29559
[15,    50] loss: 2.23123
[15,    60] loss: 2.25977
[15,    70] loss: 2.23611
[15,    80] loss: 2.26375
[15,    90] loss: 2.22107
[15,   100] loss: 2.25354
[15,   110] loss: 2.25099
[15,   120] loss: 2.25469
[15,   130] loss: 2.25553
[15,   140] loss: 2.25243
[15,   150] loss: 2.26408
[15,   160] loss: 2.27294
[15,   170] loss: 2.26128
[15,   180] loss: 2.26869
[15,   190] loss: 2.26280
[15,   200] loss: 2.27713
[15,   210] loss: 2.26264
[15,   220] loss: 2.25725
[15,   230] loss: 2.27142
[15,   240] loss: 2.25853
[15,   250] loss: 2.27299
[15,   260] loss: 2.25430
[15,   270] loss: 2.26575
[15,   280] loss: 2.25809
[15,   290] loss: 2.27270
[15,   300] loss: 2.27370
[15,   310] loss: 2.28358
[15,   320] loss: 2.24963
[15,   330] loss: 2.24296
[15,   340] loss: 2.27073
[15,   350] loss: 2.24937
[15,   360] loss: 2.27218
[15,   370] loss: 2.25720
[15,   380] loss: 2.28431
[15,   390] loss: 2.24920
--> Accuracy after epoch 14: 14 %
Epoch 15: lr = 0.008000
[16,    10] loss: 2.26486
[16,    20] loss: 2.24452
[16,    30] loss: 2.24511
[16,    40] loss: 2.25021
[16,    50] loss: 2.24274
[16,    60] loss: 2.27671
[16,    70] loss: 2.25396
[16,    80] loss: 2.26207
[16,    90] loss: 2.27328
[16,   100] loss: 2.26500
[16,   110] loss: 2.26619
[16,   120] loss: 2.27074
[16,   130] loss: 2.28487
[16,   140] loss: 2.28377
[16,   150] loss: 2.27568
[16,   160] loss: 2.25211
[16,   170] loss: 2.25318
[16,   180] loss: 2.25085
[16,   190] loss: 2.25492
[16,   200] loss: 2.28460
[16,   210] loss: 2.28162
[16,   220] loss: 2.28338
[16,   230] loss: 2.28239
[16,   240] loss: 2.26832
[16,   250] loss: 2.29243
[16,   260] loss: 2.26707
[16,   270] loss: 2.25844
[16,   280] loss: 2.27462
[16,   290] loss: 2.26669
[16,   300] loss: 2.24411
[16,   310] loss: 2.25897
[16,   320] loss: 2.27758
[16,   330] loss: 2.26256
[16,   340] loss: 2.25084
[16,   350] loss: 2.26605
[16,   360] loss: 2.28794
[16,   370] loss: 2.28083
[16,   380] loss: 2.29418
[16,   390] loss: 2.27809
--> Accuracy after epoch 15: 14 %
Epoch 16: lr = 0.008000
[17,    10] loss: 2.27182
[17,    20] loss: 2.25620
[17,    30] loss: 2.26441
[17,    40] loss: 2.26020
[17,    50] loss: 2.26104
[17,    60] loss: 2.28687
[17,    70] loss: 2.26564
[17,    80] loss: 2.27112
[17,    90] loss: 2.28562
[17,   100] loss: 2.29090
[17,   110] loss: 2.29087
[17,   120] loss: 2.27144
[17,   130] loss: 2.27415
[17,   140] loss: 2.26322
[17,   150] loss: 2.26353
[17,   160] loss: 2.28925
[17,   170] loss: 2.26865
[17,   180] loss: 2.28768
[17,   190] loss: 2.29134
[17,   200] loss: 2.29326
[17,   210] loss: 2.27652
[17,   220] loss: 2.28968
[17,   230] loss: 2.28402
[17,   240] loss: 2.27652
[17,   250] loss: 2.26778
[17,   260] loss: 2.27206
[17,   270] loss: 2.27974
[17,   280] loss: 2.28586
[17,   290] loss: 2.27787
[17,   300] loss: 2.29397
[17,   310] loss: 2.30448
[17,   320] loss: 2.30266
[17,   330] loss: 2.30057
[17,   340] loss: 2.29059
[17,   350] loss: 2.29099
[17,   360] loss: 2.28565
[17,   370] loss: 2.29133
[17,   380] loss: 2.28724
[17,   390] loss: 2.28971
--> Accuracy after epoch 16: 14 %
Epoch 17: lr = 0.008000
[18,    10] loss: 2.28487
[18,    20] loss: 2.29658
[18,    30] loss: 2.29546
[18,    40] loss: 2.29301
[18,    50] loss: 2.29228
[18,    60] loss: 2.29674
[18,    70] loss: 2.29435
[18,    80] loss: 2.29555
[18,    90] loss: 2.29541
[18,   100] loss: 2.29722
[18,   110] loss: 2.29257
[18,   120] loss: 2.29020
[18,   130] loss: 2.29091
[18,   140] loss: 2.29098
[18,   150] loss: 2.29636
[18,   160] loss: 2.28630
[18,   170] loss: 2.29833
[18,   180] loss: 2.29932
[18,   190] loss: 2.29979
[18,   200] loss: 2.30008
[18,   210] loss: 2.29521
[18,   220] loss: 2.29143
[18,   230] loss: 2.28752
[18,   240] loss: 2.29464
[18,   250] loss: 2.28659
[18,   260] loss: 2.29352
[18,   270] loss: 2.29967
[18,   280] loss: 2.29623
[18,   290] loss: 2.29557
[18,   300] loss: 2.29704
[18,   310] loss: 2.29668
[18,   320] loss: 2.29863
[18,   330] loss: 2.29707
[18,   340] loss: 2.29572
[18,   350] loss: 2.29730
[18,   360] loss: 2.29549
[18,   370] loss: 2.30068
[18,   380] loss: 2.29906
[18,   390] loss: 2.30272
--> Accuracy after epoch 17: 13 %
Epoch 18: lr = 0.008000
[19,    10] loss: 2.29829
[19,    20] loss: 2.29455
[19,    30] loss: 2.29728
[19,    40] loss: 2.29725
[19,    50] loss: 2.29534
[19,    60] loss: 2.29904
[19,    70] loss: 2.29578
[19,    80] loss: 2.30442
[19,    90] loss: 2.29906
[19,   100] loss: 2.29070
[19,   110] loss: 2.29448
[19,   120] loss: 2.29110
[19,   130] loss: 2.29897
[19,   140] loss: 2.29668
[19,   150] loss: 2.30053
[19,   160] loss: 2.29796
[19,   170] loss: 2.29797
[19,   180] loss: 2.29779
[19,   190] loss: 2.29777
[19,   200] loss: 2.29705
[19,   210] loss: 2.29791
[19,   220] loss: 2.29501
[19,   230] loss: 2.29783
[19,   240] loss: 2.29713
[19,   250] loss: 2.29370
[19,   260] loss: 2.29895
[19,   270] loss: 2.30077
[19,   280] loss: 2.29806
[19,   290] loss: 2.29479
[19,   300] loss: 2.29331
[19,   310] loss: 2.29455
[19,   320] loss: 2.29319
[19,   330] loss: 2.29777
[19,   340] loss: 2.30192
[19,   350] loss: 2.29701
[19,   360] loss: 2.29248
[19,   370] loss: 2.29476
[19,   380] loss: 2.29713
[19,   390] loss: 2.29703
--> Accuracy after epoch 18: 12 %
Epoch 19: lr = 0.008000
[20,    10] loss: 2.30414
[20,    20] loss: 2.29661
[20,    30] loss: 2.29486
[20,    40] loss: 2.29770
[20,    50] loss: 2.29891
[20,    60] loss: 2.29836
[20,    70] loss: 2.29641
[20,    80] loss: 2.29851
[20,    90] loss: 2.29844
[20,   100] loss: 2.29396
[20,   110] loss: 2.29354
[20,   120] loss: 2.29978
[20,   130] loss: 2.30319
[20,   140] loss: 2.29136
[20,   150] loss: 2.29655
[20,   160] loss: 2.29443
[20,   170] loss: 2.30373
[20,   180] loss: 2.30958
[20,   190] loss: 2.29607
[20,   200] loss: 2.30195
[20,   210] loss: 2.30238
[20,   220] loss: 2.29694
[20,   230] loss: 2.30001
[20,   240] loss: 2.29988
[20,   250] loss: 2.30190
[20,   260] loss: 2.30073
[20,   270] loss: 2.30052
[20,   280] loss: 2.30196
[20,   290] loss: 2.30258
[20,   300] loss: 2.30258
[20,   310] loss: 2.30258
[20,   320] loss: 2.30258
[20,   330] loss: 2.30258
[20,   340] loss: 2.30258
[20,   350] loss: 2.30258
[20,   360] loss: 2.30258
[20,   370] loss: 2.30258
[20,   380] loss: 2.30258
[20,   390] loss: 2.30258
--> Accuracy after epoch 19: 10 %
Epoch 20: lr = 0.006400
[21,    10] loss: 2.30258
[21,    20] loss: 2.30258
[21,    30] loss: 2.30258
[21,    40] loss: 2.30258
[21,    50] loss: 2.30258
[21,    60] loss: 2.30258
[21,    70] loss: 2.30258
[21,    80] loss: 2.30258
[21,    90] loss: 2.30258
[21,   100] loss: 2.30258
[21,   110] loss: 2.30258
[21,   120] loss: 2.30258
[21,   130] loss: 2.30258
[21,   140] loss: 2.30258
[21,   150] loss: 2.30258
[21,   160] loss: 2.30258
[21,   170] loss: 2.30258
[21,   180] loss: 2.30258
[21,   190] loss: 2.30258
[21,   200] loss: 2.30258
[21,   210] loss: 2.30258
[21,   220] loss: 2.30258
[21,   230] loss: 2.30258
[21,   240] loss: 2.30258
[21,   250] loss: 2.30258
[21,   260] loss: 2.30258
[21,   270] loss: 2.30258
[21,   280] loss: 2.30258
[21,   290] loss: 2.30258
[21,   300] loss: 2.30258
[21,   310] loss: 2.30258
[21,   320] loss: 2.30258
[21,   330] loss: 2.30258
[21,   340] loss: 2.30258
[21,   350] loss: 2.30258
[21,   360] loss: 2.30258
[21,   370] loss: 2.30258
[21,   380] loss: 2.30258
[21,   390] loss: 2.30258
--> Accuracy after epoch 20: 10 %
Epoch 21: lr = 0.006400
[22,    10] loss: 2.30258
[22,    20] loss: 2.30258
[22,    30] loss: 2.30258
[22,    40] loss: 2.30258
[22,    50] loss: 2.30258
[22,    60] loss: 2.30258
[22,    70] loss: 2.30258
[22,    80] loss: 2.30258
[22,    90] loss: 2.30258
[22,   100] loss: 2.30258
[22,   110] loss: 2.30258
[22,   120] loss: 2.30258
[22,   130] loss: 2.30258
[22,   140] loss: 2.30258
[22,   150] loss: 2.30258
[22,   160] loss: 2.30258
[22,   170] loss: 2.30258
[22,   180] loss: 2.30258
[22,   190] loss: 2.30258
[22,   200] loss: 2.30258
[22,   210] loss: 2.30258
[22,   220] loss: 2.30258
[22,   230] loss: 2.30258
[22,   240] loss: 2.30258
[22,   250] loss: 2.30258
[22,   260] loss: 2.30258
[22,   270] loss: 2.30258
[22,   280] loss: 2.30258
[22,   290] loss: 2.30258
[22,   300] loss: 2.30258
[22,   310] loss: 2.30258
[22,   320] loss: 2.30258
[22,   330] loss: 2.30258
[22,   340] loss: 2.30258
[22,   350] loss: 2.30258
[22,   360] loss: 2.30258
[22,   370] loss: 2.30258
[22,   380] loss: 2.30258
[22,   390] loss: 2.30258
--> Accuracy after epoch 21: 10 %
Epoch 22: lr = 0.006400
[23,    10] loss: 2.30258
[23,    20] loss: 2.30258
[23,    30] loss: 2.30258
[23,    40] loss: 2.30258
[23,    50] loss: 2.30258
[23,    60] loss: 2.30258
[23,    70] loss: 2.30258
[23,    80] loss: 2.30258
[23,    90] loss: 2.30258
[23,   100] loss: 2.30258
[23,   110] loss: 2.30258
[23,   120] loss: 2.30258
[23,   130] loss: 2.30258
[23,   140] loss: 2.30258
[23,   150] loss: 2.30258
[23,   160] loss: 2.30258
[23,   170] loss: 2.30258
[23,   180] loss: 2.30258
[23,   190] loss: 2.30258
[23,   200] loss: 2.30258
[23,   210] loss: 2.30258
[23,   220] loss: 2.30258
[23,   230] loss: 2.30258
[23,   240] loss: 2.30258
[23,   250] loss: 2.30258
[23,   260] loss: 2.30258
[23,   270] loss: 2.30258
[23,   280] loss: 2.30258
[23,   290] loss: 2.30258
[23,   300] loss: 2.30258
[23,   310] loss: 2.30258
[23,   320] loss: 2.30258
[23,   330] loss: 2.30258
[23,   340] loss: 2.30258
[23,   350] loss: 2.30258
[23,   360] loss: 2.30258
[23,   370] loss: 2.30258
[23,   380] loss: 2.30258
[23,   390] loss: 2.30258
--> Accuracy after epoch 22: 10 %
Epoch 23: lr = 0.006400
[24,    10] loss: 2.30258
[24,    20] loss: 2.30258
[24,    30] loss: 2.30258
[24,    40] loss: 2.30258
[24,    50] loss: 2.30258
[24,    60] loss: 2.30258
[24,    70] loss: 2.30258
[24,    80] loss: 2.30258
[24,    90] loss: 2.30258
[24,   100] loss: 2.30258
[24,   110] loss: 2.30258
[24,   120] loss: 2.30258
[24,   130] loss: 2.30258
[24,   140] loss: 2.30258
[24,   150] loss: 2.30258
[24,   160] loss: 2.30258
[24,   170] loss: 2.30258
[24,   180] loss: 2.30258
[24,   190] loss: 2.30258
[24,   200] loss: 2.30258
[24,   210] loss: 2.30258
[24,   220] loss: 2.30258
[24,   230] loss: 2.30258
[24,   240] loss: 2.30258
[24,   250] loss: 2.30258
[24,   260] loss: 2.30258
[24,   270] loss: 2.30258
[24,   280] loss: 2.30258
[24,   290] loss: 2.30258
[24,   300] loss: 2.30258
[24,   310] loss: 2.30258
[24,   320] loss: 2.30258
[24,   330] loss: 2.30258
[24,   340] loss: 2.30258
[24,   350] loss: 2.30258
[24,   360] loss: 2.30258
[24,   370] loss: 2.30258
[24,   380] loss: 2.30258
[24,   390] loss: 2.30258
--> Accuracy after epoch 23: 10 %
Epoch 24: lr = 0.006400
[25,    10] loss: 2.30258
[25,    20] loss: 2.30258
[25,    30] loss: 2.30258
[25,    40] loss: 2.30258
[25,    50] loss: 2.30258
[25,    60] loss: 2.30258
[25,    70] loss: 2.30258
[25,    80] loss: 2.30258
[25,    90] loss: 2.30258
[25,   100] loss: 2.30258
[25,   110] loss: 2.30258
[25,   120] loss: 2.30258
[25,   130] loss: 2.30258
[25,   140] loss: 2.30258
[25,   150] loss: 2.30258
[25,   160] loss: 2.30258
[25,   170] loss: 2.30258
[25,   180] loss: 2.30258
[25,   190] loss: 2.30258
[25,   200] loss: 2.30258
[25,   210] loss: 2.30258
[25,   220] loss: 2.30258
[25,   230] loss: 2.30258
[25,   240] loss: 2.30258
[25,   250] loss: 2.30258
[25,   260] loss: 2.30258
[25,   270] loss: 2.30258
[25,   280] loss: 2.30258
[25,   290] loss: 2.30258
[25,   300] loss: 2.30258
[25,   310] loss: 2.30258
[25,   320] loss: 2.30258
[25,   330] loss: 2.30258
[25,   340] loss: 2.30258
[25,   350] loss: 2.30258
[25,   360] loss: 2.30258
[25,   370] loss: 2.30258
[25,   380] loss: 2.30258
[25,   390] loss: 2.30258
--> Accuracy after epoch 24: 10 %
Finished Training
Accuracy of the network on the 10000 test images: 10 %
Saving data to mat file...
done!
