{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "*Question*: how does generalization error (error on validation set) change as we reduce the amount of unique training examples for both the subspace-constrained and non-subspace-constrained methods?\n",
    "*Hypothesis*: Subspace constrained method will have less generalization error than non subspace constrained method as the number of unique training examples decreases\n",
    "*Todo*: use subspace dimension from experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "from copy import deepcopy\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def rel_error(x, y):\n",
    "  # returns relative error\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "# Load the preprocessed CIFAR10 data.\n",
    "alldata = get_CIFAR10_data()\n",
    "for k, v in alldata.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- trial 0: 100 percent of data (49000 unique examples, 0 duplicate examples) -----\n",
      "=== TRAINING STANDARD MODEL FOR TRIAL 0 ===\n",
      "(Iteration 1 / 1960) loss: 2.304995\n",
      "(Epoch 0 / 2) train acc: 0.162000; val_acc: 0.175000\n",
      "(Iteration 21 / 1960) loss: 2.157250\n",
      "(Iteration 41 / 1960) loss: 1.967369\n",
      "(Iteration 61 / 1960) loss: 1.870945\n",
      "(Iteration 81 / 1960) loss: 1.716645\n",
      "(Iteration 101 / 1960) loss: 1.815589\n",
      "(Iteration 121 / 1960) loss: 1.715465\n",
      "(Iteration 141 / 1960) loss: 1.500106\n",
      "(Iteration 161 / 1960) loss: 1.874528\n",
      "(Iteration 181 / 1960) loss: 1.899476\n",
      "(Iteration 201 / 1960) loss: 1.594301\n",
      "(Iteration 221 / 1960) loss: 1.683984\n",
      "(Iteration 241 / 1960) loss: 1.429353\n",
      "(Iteration 261 / 1960) loss: 1.581854\n",
      "(Iteration 281 / 1960) loss: 1.497817\n",
      "(Iteration 301 / 1960) loss: 1.701874\n",
      "(Iteration 321 / 1960) loss: 1.597978\n",
      "(Iteration 341 / 1960) loss: 1.287961\n",
      "(Iteration 361 / 1960) loss: 1.658388\n",
      "(Iteration 381 / 1960) loss: 1.421290\n",
      "(Iteration 401 / 1960) loss: 1.529719\n",
      "(Iteration 421 / 1960) loss: 1.373857\n"
     ]
    }
   ],
   "source": [
    "ntrain_total = alldata['X_train'].shape[0]\n",
    "pct_train_sweep = (1, 0.8, 0.6, 0.4, 0.2)\n",
    "results_train_accuracy = np.zeros((len(pct_train_sweep),2))\n",
    "results_test_accuracy  = np.zeros((len(pct_train_sweep),2))\n",
    "for (i,pct_train) in enumerate(pct_train_sweep):\n",
    "    # -------------------------\n",
    "    # --- generate data set ---\n",
    "    # -------------------------\n",
    "    ntrain_unique = round(pct_train*ntrain_total)\n",
    "    ntrain_dupl = ntrain_total - ntrain_unique\n",
    "    ind_unique = np.arange(0,ntrain_unique)\n",
    "    ind_dupl = np.random.choice(np.arange(0,ntrain_unique),size=ntrain_dupl)\n",
    "    ind_train = np.concatenate((ind_unique, ind_dupl))\n",
    "    print('----- trial %d: %d percent of data (%d unique examples, %d duplicate examples) -----' % (i, pct_train*100, ntrain_unique, ntrain_dupl))\n",
    "    #print('unique ind:')\n",
    "    #print(ind_unique)\n",
    "    #print('duplicate ind:')\n",
    "    #print(ind_dupl)\n",
    "    data_abbrev = {\n",
    "        'X_train': deepcopy(alldata['X_train'])[ind_train,:,:,:],\n",
    "        'y_train': deepcopy(alldata['y_train'])[ind_train],\n",
    "        'X_val':   deepcopy(alldata['X_val']),\n",
    "        'y_val':   deepcopy(alldata['y_val']),\n",
    "        'X_test':  deepcopy(alldata['X_test']),\n",
    "        'y_test':  deepcopy(alldata['y_test'])\n",
    "    }\n",
    "    # --------------------------------------\n",
    "    # --- train and report test accuracy ---\n",
    "    # --------------------------------------\n",
    "    standardModel  = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=600, reg=0.001)\n",
    "    subspaceModel  = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=600, reg=0.001)\n",
    "    standardSolver = Solver(standardModel, data_abbrev,\n",
    "                            num_epochs=2, batch_size=50,\n",
    "                            update_rule='adam',\n",
    "                            optim_config={\n",
    "                              'learning_rate': 1e-4,\n",
    "                            },\n",
    "                            verbose=True, print_every=20)\n",
    "    subspaceSolver = Solver(subspaceModel, data_abbrev,\n",
    "                            num_epochs=2, batch_size=50,\n",
    "                            update_rule='adam',\n",
    "                            optim_config={\n",
    "                                'learning_rate': 1e-4,\n",
    "                            },\n",
    "                            verbose=True, print_every=20)\n",
    "    reduced_dim = 24\n",
    "    print('=== TRAINING STANDARD MODEL FOR TRIAL %d ===' % i)\n",
    "    standardSolver.train()\n",
    "    results_train_accuracy[i,0] = standardSolver.train_acc_history[-1]\n",
    "    results_test_accuracy[i,0] = subspaceSolver.check_accuracy(alldata['X_test'],alldata['y_test'])\n",
    "    print('final accuracy for %d percent of data, standard model: %.4f (train), %.4f (test)' % (pct_train*100, results_train_accuracy[i,0], results_test_accuracy[i,1]))\n",
    "    print('=== TRAINING SUBSPACE MODEL FOR TRIAL %d ===' % i)\n",
    "    subspaceSolver.train(dim=reduced_dim)\n",
    "    results_train_accuracy[i,1] = subspaceSolver.train_acc_history[-1]\n",
    "    results_test_accuracy[i,1] = subspaceSolver.check_accuracy(alldata['X_test'],alldata['y_test'])\n",
    "    print('final accuracy for %d percent of data, subspace model: %.4f (train), %.4f (test)' % (pct_train*100, results_train_accuracy[i,0], results_test_accuracy[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_train_accuracy = np.random.rand(6,2)\n",
    "#results_test_accuracy = np.random.rand(6,2)\n",
    "print(results_train_accuracy)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(results_train_accuracy[:,0], '-o')\n",
    "plt.plot(results_train_accuracy[:,1], '-o')\n",
    "plt.legend(['0', '1'], loc='upper left')\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(results_test_accuracy[:,0], '-o')\n",
    "plt.plot(results_test_accuracy[:,1], '-o')\n",
    "plt.legend(['0','1'], loc='upper left')\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
