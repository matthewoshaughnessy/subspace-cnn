{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "*Question*: how does generalization error (error on validation set) change as we reduce the amount of unique training examples for both the subspace-constrained and non-subspace-constrained methods?\n",
    "*Hypothesis*: Subspace constrained method will have less generalization error than non subspace constrained method as the number of unique training examples decreases\n",
    "*Todo*: use subspace dimension from experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "from copy import deepcopy\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def rel_error(x, y):\n",
    "  # returns relative error\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "# Load the preprocessed CIFAR10 data.\n",
    "alldata = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- trial 0: 100 percent of data (49000 unique examples, 0 duplicate examples) -----\n",
      "=== TRAINING STANDARD MODEL FOR TRIAL 0 ===\n",
      "(Iteration 1 / 1960) loss: 2.305161\n",
      "(Epoch 0 / 2) train acc: 0.104000; val_acc: 0.112000\n",
      "(Iteration 101 / 1960) loss: 1.579576\n",
      "(Iteration 201 / 1960) loss: 1.655479\n",
      "(Iteration 301 / 1960) loss: 1.463823\n",
      "(Iteration 401 / 1960) loss: 1.350504\n",
      "(Iteration 501 / 1960) loss: 1.333810\n",
      "(Iteration 601 / 1960) loss: 1.376882\n",
      "(Iteration 701 / 1960) loss: 1.440234\n",
      "(Iteration 801 / 1960) loss: 1.134020\n",
      "(Iteration 901 / 1960) loss: 1.106834\n",
      "(Epoch 1 / 2) train acc: 0.537000; val_acc: 0.552000\n",
      "(Iteration 1001 / 1960) loss: 1.711220\n"
     ]
    }
   ],
   "source": [
    "ntrain_total = data['X_train'].shape[0]\n",
    "pct_train_sweep = (1, 0.8, 0.6, 0.4, 0.2)\n",
    "results_train_accuracy = np.zeros((len(pct_train_sweep),2))\n",
    "results_test_accuracy  = np.zeros((len(pct_train_sweep),2))\n",
    "for (i,pct_train) in enumerate(pct_train_sweep):\n",
    "    # -------------------------\n",
    "    # --- generate data set ---\n",
    "    # -------------------------\n",
    "    ntrain_unique = round(pct_train*ntrain_total)\n",
    "    ntrain_dupl = ntrain_total - ntrain_unique\n",
    "    ind_unique = np.arange(0,ntrain_unique)\n",
    "    ind_dupl = np.random.choice(np.arange(0,ntrain_unique),size=)[0:ntrain_dupl]\n",
    "    ind_train = np.concatenate((ind_unique, ind_dupl))\n",
    "    print('----- trial %d: %d percent of data (%d unique examples, %d duplicate examples) -----' % (i, pct_train*100, ntrain_unique, ntrain_dupl))\n",
    "    data_abbrev['X_train'] = deepcopy(alldata['X_train'])[ind_train,:,:,:]\n",
    "    data_abbrev['y_train'] = deepcopy(alldata['y_train'])[ind_train]\n",
    "    data_abbrev['X_val']   = deepcopy(alldata['X_val'])\n",
    "    data_abbrev['y_val']   = deepcopy(alldata['y_val'])\n",
    "    data_abbrev['X_test']  = deepcopy(alldata['X_test'])\n",
    "    data_abbrev['y_test']  = deepcopy(alldata['y_test'])\n",
    "    # --------------------------------------\n",
    "    # --- train and report test accuracy ---\n",
    "    # --------------------------------------\n",
    "    standardModel  = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=600, reg=0.001)\n",
    "    subspaceModel  = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=600, reg=0.001)\n",
    "    standardSolver = Solver(standardModel, data_abbrev,\n",
    "                            num_epochs=2, batch_size=50,\n",
    "                            update_rule='adam',\n",
    "                            optim_config={\n",
    "                              'learning_rate': 1e-4,\n",
    "                            },\n",
    "                            verbose=True, print_every=100)\n",
    "    subspaceSolver = Solver(subspaceModel, data_abbrev,\n",
    "                            num_epochs=2, batch_size=50,\n",
    "                            update_rule='adam',\n",
    "                            optim_config={\n",
    "                                'learning_rate': 1e-4,\n",
    "                            },\n",
    "                            verbose=True, print_every=100)\n",
    "    ambient_dim = data_abbrev['X_train'].shape[2]*data_abbrev['X_train'].shape[3]\n",
    "    print('=== TRAINING STANDARD MODEL FOR TRIAL %d ===' % i)\n",
    "    standardSolver.train(ambient_dim)\n",
    "    results_train_accuracy[i,0] = solver.train_acc_history[-1]\n",
    "    results_test_accuracy[i,0] = solver.test_acc_history[-1]\n",
    "    print('final accuracy for %d percent of data, standard model: %.4f (train), %.4f (test)' % (pct_train*100, results_train_accuracy[i,0], results_test_accuracy[i,1]))\n",
    "    print('=== TRAINING SUBSPACE MODEL FOR TRIAL %d ===' % i)\n",
    "    subspaceSolver.train(round(0.5*ambient_dim))\n",
    "    results_train_accuracy[i,1] = subspaceSolver.train_acc_history[-1]\n",
    "    results_test_accuracy[i,1] = subspaceSolver.test_acc_history[-1]\n",
    "    print('final accuracy for %d percent of data, subspace model: %.4f (train), %.4f (test)' % (pct_train*100, results_train_accuracy[i,0], results_test_accuracy[i,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
